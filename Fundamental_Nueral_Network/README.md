# Fundamental_Nueral_Network

## Project Description
Goal: Implement an MLP for hand-written digit recognition.

Instruction:

• Read the lecture note on neural network, focusing on activation functions and the forward and backward
propagation algorithms. You should use the pseudo-codes for the mini-batch stochastic gradient descent
algorithm as a reference to implement the training algorithm.

• Dataset: the files under the “data” folder contains a train-test split of the MNIST dataset for training
and testing. For example, X train.pkl is the vectors of training examples and Y train.pkl contains
the one-hot vectors of the labels of training examples. More information about this dataset and
the current state-of-the-art classification performance can be found in https://www.kaggle.com/c/
digit-recognizer/discussion/61480. The training data has 60,000 images, each of which is a square
matrix with 28 × 28 pixels, and the test data has 10,000 images of the same format as the training
images. Each pixel represents a gray level of a particular location of an image. We have reshaped the
images into column vectors of length 28 × 28, which will be the dimension of the input layer of your
neural network. Each image is a hand-written digit in {0, 1, . . . , 9} and the neural network needs to
classify each image into one of the 10 classes. As the digits are handwritten by different persons, there
are variations in the looks of the same digit.

– problem1.py: various activation functions, including Softmax, ReLU, sigmoid, and tanh, and
the cross-entropy loss function. For functions marked with “DISREGARD THIS FUNCTION”
or raising the “NotImplementedError”, you can safely ignore them. You should vectorize these
functions as much as possible to gain speed.

– problem2.py: functions in the NN class, including forward, backward, train, and explain. The
function “explain” is required for graduates only. You should vectorize these functions as much
as possible to gain speed.

– problem3.py: training of your NN on the MNIST dataset. We will use this file for grading so
nothing should be changed in this file.

– problem4.py: explaining the output of the neurons at the last layer. Required only for graduates.
We will use this file for grading so nothing should be changed in this file.

More detailed instructions are given in the comments of the functions.
• Files test1.py and test2.py will unit-test the correctness of your implementations in the corresponding
problem1.py and problem2.py files. For example, after you implement problem1.py file, run

  nosetests -v test1

to test the correctness of your implementation of problem1.py. Note that passing the tests does not
mean your implementations are entirely correct: the test can catch only a limited number of mistakes.

If you use Anaconda (highly recommended), there should NOT be any packages you need to install.
Otherwise, you will need to install nosestest for such unit test.

• We provide simple visualization of the images and the feature map to be generated by problem4.py.
src/Visualization.ipynb
